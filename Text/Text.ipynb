{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Загрузка-данных\" data-toc-modified-id=\"Загрузка-данных-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Загрузка данных</a></span></li><li><span><a href=\"#Лемматизация\" data-toc-modified-id=\"Лемматизация-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Лемматизация</a></span></li></ul></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#Разделение-на-выборки\" data-toc-modified-id=\"Разделение-на-выборки-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Разделение на выборки</a></span></li><li><span><a href=\"#Логистическая-регрессия\" data-toc-modified-id=\"Логистическая-регрессия-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Логистическая регрессия</a></span></li><li><span><a href=\"#Случайный-лес\" data-toc-modified-id=\"Случайный-лес-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Случайный лес</a></span></li><li><span><a href=\"#Градиентный-бустинг-Catboost\" data-toc-modified-id=\"Градиентный-бустинг-Catboost-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Градиентный бустинг Catboost</a></span></li><li><span><a href=\"#Работа-с-дисбалансом\" data-toc-modified-id=\"Работа-с-дисбалансом-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Работа с дисбалансом</a></span></li><li><span><a href=\"#Вывод-по-результатам-обучения\" data-toc-modified-id=\"Вывод-по-результатам-обучения-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>Вывод по результатам обучения</a></span></li><li><span><a href=\"#Тестирование\" data-toc-modified-id=\"Тестирование-2.7\"><span class=\"toc-item-num\">2.7&nbsp;&nbsp;</span>Тестирование</a></span></li></ul></li><li><span><a href=\"#Общий-вывод\" data-toc-modified-id=\"Общий-вывод-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Общий вывод</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline as imbPipeline\n",
    "from imblearn.over_sampling import RandomOverSampler,  SMOTE\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import  f1_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "\n",
    "import spacy\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "     df = pd.read_csv(r\"C:\\Проекты Яндекс.Практикум\\13. Машинное обучение для текстов\\Датасет\\toxic_comments.csv\")\n",
    "except: \n",
    "    df=pd.read_csv('/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузили необходимые библиотеки и датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4           4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143106\n",
       "1     16186\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    159292.000000\n",
       "mean      79725.697242\n",
       "std       46028.837471\n",
       "min           0.000000\n",
       "25%       39872.750000\n",
       "50%       79721.500000\n",
       "75%      119573.250000\n",
       "max      159450.000000\n",
       "Name: Unnamed: 0, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Unnamed: 0'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Датасет состоит из трех столбцов:\n",
    "- text, с комментариями на английском\n",
    "- toxic, с классификацией по токсичности. Положительного класса 16 тыс записей, отрицательного 143 тыс. Разница в 8.8 раз\n",
    "- Unnamed: 0, неинформативный столбеЦ, который можно удалить. Данные в столбце частично дублируют индексы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалили столбец Unnamed: 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Лемматизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 159292/159292 [14:38<00:00, 181.32it/s]\n"
     ]
    }
   ],
   "source": [
    "new_corpus = []\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "for doc in tqdm(nlp.pipe(df['text'], batch_size=64, n_process=-1, disable=[\"parser\", \"ner\"]), total=len(df['text'])):\n",
    "    word_list = [tok.lemma_ for tok in doc]\n",
    "    new_corpus.append(' '.join(word_list))\n",
    "    \n",
    "df['lemm_spacy_new'] = new_corpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 159292/159292 [00:09<00:00, 17138.53it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "def clear_text(text):\n",
    "  cleared_text = re.sub(r'[^a-zA-Z]', ' ',text)\n",
    "  cleared_text = cleared_text.lower()\n",
    "  return ' '.join(cleared_text.split())\n",
    "\n",
    "df['clear_text'] = df['lemm_spacy_new'].progress_apply(clear_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemm_spacy_new</th>\n",
       "      <th>clear_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>Explanation \\n why the edit make under my user...</td>\n",
       "      <td>explanation why the edit make under my usernam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>D'aww ! he match this background colour I be s...</td>\n",
       "      <td>d aww he match this background colour i be see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man , I be really not try to edit war . it...</td>\n",
       "      <td>hey man i be really not try to edit war it be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>\" \\n More \\n I can not make any real suggestio...</td>\n",
       "      <td>more i can not make any real suggestion on imp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>you , sir , be my hero . any chance you rememb...</td>\n",
       "      <td>you sir be my hero any chance you remember wha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                      lemm_spacy_new  \\\n",
       "0  Explanation \\n why the edit make under my user...   \n",
       "1  D'aww ! he match this background colour I be s...   \n",
       "2  hey man , I be really not try to edit war . it...   \n",
       "3  \" \\n More \\n I can not make any real suggestio...   \n",
       "4  you , sir , be my hero . any chance you rememb...   \n",
       "\n",
       "                                          clear_text  \n",
       "0  explanation why the edit make under my usernam...  \n",
       "1  d aww he match this background colour i be see...  \n",
       "2  hey man i be really not try to edit war it be ...  \n",
       "3  more i can not make any real suggestion on imp...  \n",
       "4  you sir be my hero any chance you remember wha...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemm_spacy_new</th>\n",
       "      <th>clear_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>Explanation \\n why the edit make under my user...</td>\n",
       "      <td>explanation why the edit make under my usernam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>D'aww ! he match this background colour I be s...</td>\n",
       "      <td>d aww he match this background colour i be see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man , I be really not try to edit war . it...</td>\n",
       "      <td>hey man i be really not try to edit war it be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>\" \\n More \\n I can not make any real suggestio...</td>\n",
       "      <td>more i can not make any real suggestion on imp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>you , sir , be my hero . any chance you rememb...</td>\n",
       "      <td>you sir be my hero any chance you remember wha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                      lemm_spacy_new  \\\n",
       "0  Explanation \\n why the edit make under my user...   \n",
       "1  D'aww ! he match this background colour I be s...   \n",
       "2  hey man , I be really not try to edit war . it...   \n",
       "3  \" \\n More \\n I can not make any real suggestio...   \n",
       "4  you , sir , be my hero . any chance you rememb...   \n",
       "\n",
       "                                          clear_text  \n",
       "0  explanation why the edit make under my usernam...  \n",
       "1  d aww he match this background colour i be see...  \n",
       "2  hey man i be really not try to edit war it be ...  \n",
       "3  more i can not make any real suggestion on imp...  \n",
       "4  you sir be my hero any chance you remember wha...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разделение на выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df['clear_text']\n",
    "target = df['toxic']\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size = 0.3, random_state=42) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "0.7696410556545855 лучшие параметры: {'tfidf__ngram_range': (1, 3), 'tfidf__max_df': 0.5, 'logreg__class_weight': 'balanced', 'logreg__C': 6}\n",
      "Wall time: 38min 34s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2314.76"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "start = time.time()\n",
    "\n",
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words=stopwords)),\n",
    "    ('logreg', LogisticRegression(random_state=42)),\n",
    "])\n",
    "parameters = {\n",
    "    'tfidf__max_df': (0.25, 0.5, 0.75),\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'logreg__C': [1,2, 6], \n",
    "    'logreg__class_weight': [None, 'balanced']\n",
    "    \n",
    "}\n",
    "\n",
    "grid_search_tune = RandomizedSearchCV(pipeline, parameters, cv=3, n_jobs=-1, scoring='f1', verbose=3)\n",
    "grid_search_tune.fit(features_train, target_train)\n",
    "print(grid_search_tune.best_score_, 'лучшие параметры:', grid_search_tune.best_params_)\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "round(end-start,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "0.3284908223884859 лучшие параметры: {'tfidf__ngram_range': (1, 1), 'tfidf__max_df': 0.25, 'ranfor__n_estimators': 200, 'ranfor__max_depth': 3, 'ranfor__class_weight': 'balanced'}\n",
      "Wall time: 8min 36s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "516.45"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "start = time.time()\n",
    "\n",
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words=stopwords)),\n",
    "    ('ranfor', RandomForestClassifier(random_state=42)),\n",
    "])\n",
    "parameters = {\n",
    "    'tfidf__max_df': (0.25, 0.5, 0.75, 0.9),\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'ranfor__max_depth': [3,13,2], \n",
    "    'ranfor__n_estimators': [10,200,10], \n",
    "    'ranfor__class_weight': [None, 'balanced']\n",
    "    \n",
    "}\n",
    "\n",
    "grid_search_tune = RandomizedSearchCV(pipeline, parameters, cv=3, n_jobs=-1, scoring='f1', verbose=3)\n",
    "grid_search_tune.fit(features_train, target_train)\n",
    "print(grid_search_tune.best_score_, 'лучшие параметры:', grid_search_tune.best_params_)\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "round(end-start,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Градиентный бустинг Catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ссылка на CatBoostClassifier, проведенный в Google Colab https://colab.research.google.com/drive/1__Qdi36DVzOjeQrn7miZYsrOask5zRPZ?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Работа с дисбалансом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Best score: 0.775580166595057, Best params: {'tfidf__ngram_range': (1, 2), 'tfidf__max_df': 0.25, 'logreg__C': 2}\n"
     ]
    }
   ],
   "source": [
    "pipeline_oversampling = imbPipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('oversampling', RandomOverSampler(random_state=0)),\n",
    "    ('logreg', LogisticRegression(random_state=42))])\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    'tfidf__max_df': (0.25, 0.5, 0.75),\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'logreg__C': [1,2,6]\n",
    "}\n",
    "\n",
    "grid_search_tune = RandomizedSearchCV(pipeline_oversampling, parameters, cv=3, n_jobs=-1, scoring='f1', verbose=3)\n",
    "grid_search_tune.fit(features_train, target_train)\n",
    "\n",
    "print(f\"Best score: {abs(grid_search_tune.best_score_)}, Best params: {grid_search_tune.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод по результатам обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделили данные на обучаюшую (0.7) и тестовую (0.3) выборки. \n",
    "На каждой модели провели векторизацию и обучение с подбором гиперпараметров (в том числе с балансировкой классов) через  RandomizedSearchCV.\n",
    "- Логистическая регрессия: F1 = 0.769, гиперпараметры векторизатора: ngram_range = (1, 3), max_df = 0.5, гиперпараметы модели class_weight = balanced,  C = 6.\n",
    "- Случайный лес: F1 = 0.328, гиперпараметры векторизатора: ngram_range = (1, 1), max_df = 0.25, гиперпараметы модели  n_estimators = 200, max_depth = 3,  class_weight = balanced \n",
    "- CatBoost : F1 = 0.774, гиперпараметры модели: class_weights =[1, 8.87], depth = 10, l2_leaf_reg = 3, learning_rate = 0.3\n",
    "- Логистическая регрессия с уменьшением отрицательного класса: F1 = Best score: 0.775 гиперпараметры векторизатора: ngram_range = (1, 2), max_df = 0.25, гиперпараметы модели: C = 2.\n",
    "\n",
    "Для тестирования выбрана первая модель (Логистическая регрессия), как более стабильная по сравнению с Логистической регрессией обученной на уменьшенной выборке. И более быстрая и легкая  в обучении по сравнению с CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords , max_df = 0.5, ngram_range = (1, 3))\n",
    "tf_idf_train = count_tf_idf.fit_transform(features_train)\n",
    "tf_idf_test = count_tf_idf.transform(features_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Логистическая регрессия - F1 на тестовой выборке: 0.7695789059425423\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=42, C = 6, class_weight = 'balanced')\n",
    "model.fit(tf_idf_train , target_train)\n",
    "predict_log_test = model.predict(tf_idf_test )\n",
    "f_1_lof_test=f1_score(predict_log_test, target_test )\n",
    "print('Логистическая регрессия - F1 на тестовой выборке:', f_1_lof_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Общий вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проект выполнен для интернет-магазина «Викишоп». Магазин запустил сервис редактирования описания товаров клиентами.\n",
    "В процессе выполения проекта решалась задача обучения модели классифицировать описание на позитивные и негативные. Язык комментариев - английский.\n",
    "\n",
    "Был получен датасет со 159292 комментариями с классификацией токсичности. Данные были очищены от неифоративного столбца. Тексты комментариев были лемматизированы с помощью лемматизатора Spacy.\n",
    "\n",
    "Обучили несколько моделей. На каждой модели провели векторизацию и обучение с подбором гиперпараметров (в том числе с балансировкой классов) через RandomizedSearchCV.\n",
    "\n",
    "- Логистическая регрессия: F1 = 0.769, гиперпараметры векторизатора: ngram_range = (1, 3), max_df = 0.5, гиперпараметы модели class_weight = balanced, C = 6.\n",
    "- Случайный лес: F1 = 0.328, гиперпараметры векторизатора: ngram_range = (1, 1), max_df = 0.25, гиперпараметы модели n_estimators = 200, max_depth = 3, class_weight = balanced\n",
    "- CatBoost : F1 = 0.774, гиперпараметры модели: class_weights =[1, 8.87], depth = 10, l2_leaf_reg = 3, learning_rate = 0.3\n",
    "- Логистическая регрессия с уменьшением отрицательного класса: F1 = Best score: 0.775 гиперпараметры векторизатора: ngram_range = (1, 2), max_df = 0.25, гиперпараметы модели: C = 2.\n",
    "\n",
    "Для тестирования выбрана первая модель (Логистическая регрессия), как более стабильная по сравнению с Логистической регрессией обученной на уменьшенной выборке. И более быстрая и легкая в обучении по сравнению с CatBoost.\n",
    "\n",
    "Проверенная не тестировании модель дала результат F1 = 0.769. Модель пригодна для использования."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "818.667px",
    "left": "25px",
    "top": "112.229px",
    "width": "302.375px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
